import sys
sys.path.append("../")
import fire
import torch
import torch.nn as nn
import numpy as np
from scripts.optimize import Optimize
from lolbo.molecule_objective_jtvae import MoleculeObjective
from lolbo.utils.mol_utils.load_data import load_molecule_train_data, compute_train_zs
import rdkit,sys,os
from rdkit import Chem,DataStructs
from rdkit.Chem import MolFromSmiles, MolToSmiles,AllChem
from rdkit.Chem import Descriptors
from rdkit.Chem import rdmolops, RDConfig
from tqdm.auto import tqdm
sys.path.append('%s/../JTVAE-GA/fast_jtnn/' % os.path.dirname(os.path.realpath(__file__)))
from mol_tree import Vocab, MolTree
from jtprop_vae import JTPropVAE
from jtnn_enc import JTNNEncoder
from jtmpn import JTMPN
from mpn import MPN
from nnutils import create_var
from datautils import tensorize_prop,smiles_to_moltree

class MoleculeOptimization(Optimize):
    """
    Run LOLBO Optimization for any Molecular Optimization Task using the SELFIES VAE 
    (Must be either a GuacaMol Task or the Penalized LogP task)

    Args:
        path_to_vae_statedict: Path to state dict of pretrained SELFIES VAE,
        max_string_length: Limit on string length that can be generated by VAE (without a limit we can run into OOM issues)
    """
    def __init__(
        self,
        smiles_path:str='smiles.txt',
        z_path:str='z.txt',
        y_path:str='y.txt',
        path_to_vae_statedict: str="model",
        vocab_path:str='vocab.txt', 
        hidden_size:int=450, 
        latent_size:int=56, 
        depthT:int=20, 
        depthG:int=3,
        beta:float=0.2,
        **kwargs
    ):
        self.path_to_vae_statedict = path_to_vae_statedict
        self.data_path = {
            'x':smiles_path,
            'z':z_path,
            'y':y_path
        }
        
        vocab = [x.strip("\r\n ") for x in open(vocab_path)] 
        vocab = Vocab(vocab)
        self.vae_hyper = {
            'vocab':vocab, 
            'hidden_size':hidden_size, 
            'latent_size':latent_size, 
            'depthT':depthT, 
            'depthG':depthG
        }
        self.beta = beta

        super().__init__(**kwargs)

        # add args to method args dict to be logged by wandb
        self.method_args['molopt'] = locals()
        del self.method_args['molopt']['self']

    def initialize_objective(self):
        # initialize molecule objective
        self.objective = MoleculeObjective(
            task_id=self.task_id,
            path_to_vae_statedict=self.path_to_vae_statedict,
            decoded_smiles = self.init_decoded_smiles,
            vae_hyper=self.vae_hyper,
            beta=self.beta
        )
        # if train zs have not been pre-computed for particular vae, compute them 
        #   by passing initialization selfies through vae 
        if self.init_train_z is None:
            self.init_train_z = compute_train_zs(
                self.objective,
                self.init_train_x,
            )

        return self

    def load_train_data(self):
        ''' Load in or randomly initialize self.num_initialization_points
            total initial data points to kick-off optimization 
            Must define the following:
                self.init_train_x (a list of x's)
                self.init_train_y (a tensor of scores/y's)
                self.init_train_z (a tensor of corresponding latent space points)
            '''
        assert self.num_initialization_points <= 20_000 
        with open(self.data_path['x'],'r') as f:
            smiles = [line.rstrip('\n') for line in f][0:self.num_initialization_points]
        zs = torch.from_numpy(np.loadtxt(self.data_path['z'])[0:self.num_initialization_points]).float()
        ys = torch.from_numpy(np.loadtxt(self.data_path['y'])[0:self.num_initialization_points]).float().unsqueeze(-1)
        self.init_train_x, self.init_train_z, self.init_train_y = smiles, zs, ys
        if self.verbose:
            print("Loaded initial training data")
            print("train y shape:", self.init_train_y.shape)
            print(f"train x list length: {len(self.init_train_x)}\n")

        # create initial smiles
        self.init_decoded_smiles = smiles

        return self 


if __name__ == "__main__":
    fire.Fire(MoleculeOptimization)
